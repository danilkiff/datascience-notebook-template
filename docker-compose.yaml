# SPDX-License-Identifier: Unlicense
services:
  jupyter:
    build:
      context: .
      dockerfile: Dockerfile.jupyter
    container_name: jupyter
    restart: unless-stopped
    command: >
      jupyter lab
        --ip=0.0.0.0
        --no-browser
        --IdentityProvider.token='${JUPYTER_TOKEN}'
        --ServerApp.log_level=WARN
    ports:
      - 8888:8888
    volumes:
      - ./workspace:/home/${NB_USER}
    working_dir: /home/${NB_USER}
    environment:
      NB_USER: ${NB_USER}
      NB_UID: ${NB_UID}
      NB_GID: ${NB_GID}
      CHOWN_HOME: "yes"
      MLFLOW_TRACKING_URI: http://mlflow:5000
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      AWS_ENDPOINT_URL: http://s3:9000
    shm_size: ${SHM_SIZE:-2g}
    deploy:
      resources:
        limits:
          cpus: "${JUPYTER_CPU_LIMIT:-4}"
          memory: ${JUPYTER_MEM_LIMIT:-8g}
    healthcheck:
      test: curl -f http://localhost:8888/api
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 5s
    depends_on:
      mlflow:
        condition: service_healthy
    networks:
      - frontend

  s3:
    image: minio/minio:RELEASE.2025-09-07T16-13-09Z
    container_name: mlflow_s3
    restart: unless-stopped
    command: server /data --console-address ":9001"
    ports:
      - "${MINIO_CONSOLE_PORT}:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    volumes:
      - minio_data:/data
    deploy:
      resources:
        limits:
          cpus: "${MINIO_CPU_LIMIT:-1}"
          memory: ${MINIO_MEM_LIMIT:-1g}
    healthcheck:
      # https://github.com/minio/minio/issues/18373#issuecomment-1790003599
      test: timeout 5s bash -c ':> /dev/tcp/127.0.0.1/9000' || exit 1
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 5s
    networks:
      - backend
      - frontend

  init_s3:
    image: minio/mc:RELEASE.2025-08-13T08-35-41Z
    container_name: mlflow_init_s3
    depends_on:
      s3:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set minio http://s3:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD} &&
      mc mb -p minio/${MINIO_BUCKET} || true &&
      mc version enable minio/${MINIO_BUCKET} || true &&
      mc mb -p minio/${DVC_BUCKET:-dvc} || true
      "
    restart: "no"
    networks:
      - backend

  postgres:
    image: postgres:17.8
    container_name: mlflow_postgres
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          cpus: "${POSTGRES_CPU_LIMIT:-1}"
          memory: ${POSTGRES_MEM_LIMIT:-1g}
    healthcheck:
      test: pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB} || exit 1
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 5s
    networks:
      - backend

  mlflow:
    build:
      context: .
      dockerfile: Dockerfile.mlflow
    container_name: mlflow_server
    restart: unless-stopped
    environment:
      MLFLOW_S3_ENDPOINT_URL: http://s3:9000
      AWS_ACCESS_KEY_ID: ${MINIO_ROOT_USER}
      AWS_SECRET_ACCESS_KEY: ${MINIO_ROOT_PASSWORD}
      UVICORN_ACCESS_LOG: "0"
    deploy:
      resources:
        limits:
          cpus: "${MLFLOW_CPU_LIMIT:-1}"
          memory: ${MLFLOW_MEM_LIMIT:-1g}
    depends_on:
      postgres:
        condition: service_healthy
      s3:
        condition: service_healthy
      init_s3:
        condition: service_completed_successfully
    ports:
      - "${MLFLOW_PORT}:5000"
    command: >
      server
        --backend-store-uri postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
        --serve-artifacts
        --artifacts-destination s3://${MINIO_BUCKET}
        --host 0.0.0.0
        --port 5000
        --allowed-hosts mlflow,mlflow:5000,localhost,localhost:5000,localhost:${MLFLOW_PORT:-5050}
    healthcheck:
      test: wget -qO- http://localhost:5000/ >/dev/null 2>&1 || exit 1
      interval: 5s
      timeout: 5s
      retries: 10
      start_period: 5s
    networks:
      - frontend
      - backend

  prometheus:
    image: prom/prometheus:v3.5.1
    container_name: prometheus
    restart: unless-stopped
    profiles:
      - monitoring
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    healthcheck:
      test: wget -qO- http://localhost:9090/-/healthy >/dev/null 2>&1 || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - backend

  grafana:
    image: grafana/grafana:11.6.0
    container_name: grafana
    restart: unless-stopped
    profiles:
      - monitoring
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    environment:
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_PASSWORD:-admin}
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
    healthcheck:
      test: wget -qO- http://localhost:3000/api/health >/dev/null 2>&1 || exit 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    depends_on:
      prometheus:
        condition: service_healthy
    networks:
      - backend

networks:
  frontend: {}
  backend: {}

volumes:
  postgres_data: {}
  minio_data: {}
